<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--Description-->
    
        <meta name="description" content="读这篇文章有感。我来总结一下，便于记忆。

最小二乘法（Least Square Method）适用于二维空间，用直线 y=ax+b 对二维空间（平面）的数据进行拟合。将true label与直线评测出的值的偏差的平方和作为最小条件来选择参数a，b。



线性回归（Linear Regressio">
    

    <!--Author-->
    
        <meta name="author" content="An Jingjing">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="最小二乘法到线性回归到逻辑回归再到梯度下降算法"/>
    

    <!--Open Graph Description-->
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="An&#39;s Blog"/>

    <!--Type page-->
    
        <meta property="og:type" content="article" />
    

    <!--Page Cover-->
    

        <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>最小二乘法到线性回归到逻辑回归再到梯度下降算法 - An&#39;s Blog</title>

    <!-- Bootstrap Core CSS -->
    <link href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet"/>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/style.css">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Google Analytics -->
    
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-109494500-1', 'auto');
        ga('send', 'pageview');

    </script>



    <!-- favicon -->
    
	
</head>


<body>

    <!-- Menu -->
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Logical World</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                
                    <li>
                        <a href="/">
                            
                                Home
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/archives">
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/tags">
                            
                                Tags
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="/categories">
                            
                                Categories
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="http://www.jianshu.com/u/fd50a7c19306">
                            
                                My Jianshu
                            
                        </a>
                    </li>
                
                    <li>
                        <a href="https://www.zhihu.com/people/crystalajj">
                            
                                My Zhihu
                            
                        </a>
                    </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

    <!-- Main Content -->
    <!-- Page Header -->
<!-- Set your background image for this header in your post front-matter: cover -->

<header class="intro-header" style="background-image: url('http://www.codeblocq.com/assets/projects/hexo-theme-clean-blog/img/home-bg.jpg')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <h1>最小二乘法到线性回归到逻辑回归再到梯度下降算法</h1>
                    
                    <span class="meta">
                        <!-- Date and Author -->
                        
                        
                            2017.06.07
                        
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Tags and categories -->
           
                <div class="col-lg-4 col-lg-offset-2 col-md-5 col-md-offset-1 post-tags">
                    
                        

<a href="/categories/Algorithm/">Algorithm</a>

                    
                </div>
                <div class="col-lg-4 col-md-5 post-categories">
                    
                </div>
            

            <!-- Gallery -->
            

            <!-- Post Main Content -->
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <p>读<a href="https://mp.weixin.qq.com/s/d-Bz2mjiJ9iDLTnnDx9Wmg" target="_blank" rel="external">这篇文章</a>有感。<br>我来总结一下，便于记忆。</p>
<ul>
<li>最小二乘法（Least Square Method）适用于二维空间，用直线 y=ax+b 对二维空间（平面）的数据进行拟合。将true label与直线评测出的值的<strong>偏差的平方和</strong>作为最小条件来选择参数a，b。</li>
</ul>
<p><img src="http://upload-images.jianshu.io/upload_images/8741154-d45e52bd9b26869d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="最小二乘法"></p>
<ul>
<li>线性回归（Linear Regression）将最小二乘法拓展到多维空间，用超平面 y=<strong><em>W</em></strong>x+<strong><em>b</em></strong> 对多维空间的数据进行拟合。 与最小二乘法类似，将true label与超平面评测出的值的<strong>偏差的平方和</strong>作为最小条件来选择参数<strong><em>W</em></strong>，<strong><em>b</em></strong>。</li>
</ul>
<p><img src="http://upload-images.jianshu.io/upload_images/8741154-9d04b79d44b5e1a4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="线性回归"></p>
<ul>
<li>逻辑回归（Logistics Regression）仅仅是在线性回归模型外面加了一层映射函数（sigmoid函数）。逻辑回归其实是一种分类模型!<br><a href="http://upload-images.jianshu.io/upload_images/8741154-35806bbafeba079e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" target="_blank" rel="external">sigmoid函数</a>其中，z=<strong><em>W</em></strong>x+<strong><em>b</em></strong>(线性回归模型)，若z很大，则f(z) ≈1；若z很小，则f(z)≈0。</li>
</ul>
<blockquote>
<p>二分类问题中使用sigmoid函数，多分类问题中使用softmax函数。</p>
</blockquote>
<h1 id="逻辑回归模型详解"><a href="#逻辑回归模型详解" class="headerlink" title="逻辑回归模型详解"></a>逻辑回归模型详解</h1><h3 id="逻辑回归模型的成本函数推导："><a href="#逻辑回归模型的成本函数推导：" class="headerlink" title="逻辑回归模型的成本函数推导："></a>逻辑回归模型的成本函数推导：</h3><p><img src="http://upload-images.jianshu.io/upload_images/8741154-ea668c1a2b4e6247.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="逻辑回归模型的成本函数推导过程"></p>
<p>可以看到，此处用了<strong><em>交叉熵损失函数</em></strong>来作为成本函数。</p>
<h4 id="那么为什么使用交叉熵而不是二次代价函数（最小二乘法）来定义呢？"><a href="#那么为什么使用交叉熵而不是二次代价函数（最小二乘法）来定义呢？" class="headerlink" title="那么为什么使用交叉熵而不是二次代价函数（最小二乘法）来定义呢？"></a>那么为什么使用交叉熵而不是二次代价函数（最小二乘法）来定义呢？</h4><p>原因如下：</p>
<ul>
<li><p>为什么不用二次代价函数？</p>
<ul>
<li>对于多元函数，由于变量过多，用最小二乘法定义的成本函数（损失函数）并不是在整个集合上都是凸函数，很难进行优化。</li>
<li>由于逻辑回归模型使用了sigmoid函数作为激活函数，根据sigmoid函数的性质，函数值趋近于0和1的时候梯度值过小，会导致在后续梯度下降算法中参数收敛速度过慢。</li>
</ul>
</li>
<li><p>为什么用交叉熵损失函数？</p>
<ul>
<li>交叉熵代价函数的两个性质<ul>
<li>非负性（所以我们的目标就是最小化代价函数）</li>
<li>当true label与预测值接近时，代价函数接近于0</li>
</ul>
</li>
<li>可以克服二次代价函数更新过慢的问题。根据梯度下降算法可知，当误差大的时候参数更新越快；误差小的时候参数更新越慢。</li>
</ul>
</li>
</ul>
<h3 id="优化算法（成本函数最小化方法）："><a href="#优化算法（成本函数最小化方法）：" class="headerlink" title="优化算法（成本函数最小化方法）："></a>优化算法（成本函数最小化方法）：</h3><p>采用<strong><em>随机梯度下降</em></strong>方法来最小化交叉熵成本函数。</p>
<blockquote>
<p>梯度下降（Gradient Descent）：朝着梯度的反方向迭代地调整参数直到收敛。</p>
</blockquote>
<p><strong><em>Note：</em></strong><br>梯度下降的几何意义描述：梯度下降实际上是一个“下坡”的过程。在每一个点上，我们希望往下走一步（假设一步为固定值0.5米），使得下降的高度最大，那么我们就要选择坡度变化率最大的方向往下走，这个方向就是成本函数在这一点梯度的反方向。每走一步，我们都要重新计算函数在当前点的梯度，然后选择梯度的反方向作为走下去的方向。随着每一步迭代，梯度不断地减小，到最后减小为零。</p>
<blockquote>
<p>梯度的反方向是函数值下降最快的方向，故用<strong>梯度下降法</strong>寻找局部最小值，梯度的方向是函数值上升最快的方向，故用<strong>梯度上升法</strong>寻找局部最大值。</p>
</blockquote>
<p><strong>梯度下降图解：</strong></p>
<p><img src="http://upload-images.jianshu.io/upload_images/8741154-2c60415ef129337a.jpeg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="梯度下降"></p>
<p><em>参数的更新公式为</em><br><img src="http://upload-images.jianshu.io/upload_images/8741154-718dc48cfcfde042.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="参数更新"></p>
<h3 id="梯度下降法详解"><a href="#梯度下降法详解" class="headerlink" title="梯度下降法详解"></a>梯度下降法详解</h3><p><strong>随机梯度下降（Stochastic Gradient Descent）</strong>：</p>
<p>最小化每条样本的损失函数。</p>
<ul>
<li><p>优点：收敛速度快。虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近。</p>
</li>
<li><p>缺点：因为计算得到的并不是准确的一个梯度，容易陷入到局部最优解中。</p>
</li>
</ul>
<p><strong>批量梯度下降（Batch Gradient Descent）</strong>：</p>
<p>最小化所有训练样本的损失函数，使得最终求解的是全局的最优解，即求解的参数是使得风险函数最小。</p>
<ul>
<li>优点：得到的是一个全局最优解</li>
<li>缺点：每迭代一步，都要用到训练集所有的数据，如果数据集很大，这种方法的迭代速度会很慢。</li>
</ul>
<hr>
<p><strong><em>对比：</em></strong>  </p>
<p><strong>随机梯度下降</strong>是通过每个样本来迭代更新一次，如果样本量很大的情况（例如几十万），那么可能只用其中几万条或者几千条的样本，就已经将theta迭代到最优解了，对比<strong>批量梯度下降</strong>，迭代一次需要用到几十万训练样本，一次迭代不可能最优，如果迭代10次的话就需要遍历训练样本10次。但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。</p>
<hr>
<p><strong><em>Mini-batch梯度下降</em></strong></p>
<p>这是介于BSD和SGD之间的一种优化算法。每次选取一定量的训练样本进行迭代。此算法是将批量梯度下降法中m替换成mini-batch，将mini-bach的size设置为远小于m的大小。<br>在吴恩达的机器学习课程中讲到可以将m使用b来代替，循环m/b次直到收敛或是循环次数达到。</p>
<ul>
<li>优点：得到的是一个局部近似解，但是其所计算的时间和效果要比随机梯度下降法的好。</li>
<li>缺点：但是在计算时候多了一个参数 b （即每批的大小）需要去调试。</li>
</ul>
<p><strong><em>带Mini-batch的随机梯度下降</em></strong></p>
<ul>
<li>选择n个训练样本（n&lt;m，m为总训练集样本数）</li>
<li>在这n个样本中进行n次迭代，即每次使用1个样本</li>
<li>对n次迭代得出的n个gradient进行加权平均再并求和，作为这一次mini-batch下降梯度</li>
<li>不断在训练集中重复以上步骤，直到收敛。</li>
</ul>


                
            </div>

            <!-- Comments -->
            
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    


    <hr />
    <h3>Kommentare:</h3>
    <div id="fb-root"></div>
    <script>
        (function(d, s, id) {
            var js, fjs = d.getElementsByTagName(s)[0];
            if (d.getElementById(id)) return;
            js = d.createElement(s); js.id = id;
            js.src = "//connect.facebook.net/en_US/all.js#xfbml=1&appId=824671024381046";
            fjs.parentNode.insertBefore(js, fjs);
        }(document, 'script', 'facebook-jssdk'));
    </script>

    <div class="fb-comments" data-href="http://yoursite.com/2017/06/07/逻辑回归模型详解/index.html" data-num-posts="5" data-width="100%" data-colorscheme="light"></div>

                </div>
            
        </div>
    </div>
</article>

    <!-- Footer -->
    <hr />

<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    

                    
                        <li>
                            <a href="https://www.facebook.com/AnJingjing511" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    

                    
                        <li>
                            <a href="https://github.com/crystalajj" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    

                    

                    

                    
                </ul>
                <p class="copyright text-muted">&copy; 2017 An Jingjing<br></p>
                <p class="copyright text-muted">Original Theme <a target="_blank" href="http://startbootstrap.com/template-overviews/clean-blog/">Clean Blog</a> from <a href="http://startbootstrap.com/" target="_blank">Start Bootstrap</a></p>
                <p class="copyright text-muted">Adapted for <a target="_blank" href="https://hexo.io/">Hexo</a> by <a href="http://www.codeblocq.com/" target="_blank">Jonathan Klughertz</a></p>
            </div>
        </div>
    </div>
</footer>


    <!-- After footer scripts -->
    
<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Bootstrap -->
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Disqus Comments -->



</body>

</html>